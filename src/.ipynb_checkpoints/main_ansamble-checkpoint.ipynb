{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メインのノートブック (データマイニングのアンサンブル学習)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要モジュールの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.randomforest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d527e7b276c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomforest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRF_train_and_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBM_train_and_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGB_train_and_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.randomforest'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import xgboost as xgbt\n",
    "import warnings\n",
    "import pydotplus as pdp\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
    "from sklearn import tree\n",
    "from models.randomforest import RF_train_and_predict\n",
    "from models.lgbm import LGBM_train_and_predict\n",
    "from models.xgboost import XGB_train_and_predict\n",
    "from models.catboost import CAT_train_and_predict\n",
    "from models.adaboost import AD_train_and_predict\n",
    "from __init__ import *\n",
    "from tools.lime import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 説明変数と目的変数の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7aa48f45368d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feats: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtarget_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target_name: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target_name'"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_path = '../config/default.json'\n",
    "config = json.load(open(file_path,'r',encoding=\"shift_jis\"))\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "logging.basicConfig(\n",
    "    filename='../logs/log_{0:%Y%m%d%H%M%S}.log'.format(now), level=logging.DEBUG\n",
    ")\n",
    "logging.debug('../logs/log_{0:%Y%m%d%H%M%S}.log'.format(now))\n",
    "\n",
    "feats = config['features']\n",
    "logging.debug('feats: {}'.format(feats))\n",
    "\n",
    "target_name = config['target_name']\n",
    "logging.debug('target_name: {}'.format(target_name))\n",
    "\n",
    "X_train_all = load_datasets(feats)\n",
    "logging.debug('X_train_all.shape: {}'.format(X_train_all.shape))\n",
    "\n",
    "y_train_all = load_target(target_name)\n",
    "logging.debug('y_train_all.shape: {}'.format(y_train_all.shape))\n",
    "\n",
    "# random_state_value\n",
    "random_state=0\n",
    "\n",
    "(train_x, test_x, train_y, test_y) = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第1モデルを作成(randomForest,Lightgbm,catboost,xgboost,adaboost)\n",
    "\n",
    "model_rf = RF_train_and_predict(X_train_all, y_train_all)\n",
    "model_lgbm = LGBM_train_and_predict(X_train_all, y_train_all)\n",
    "model_cat = CAT_train_and_predict(X_train_all, y_train_all)\n",
    "model_xgb = XGB_train_and_predict(X_train_all, y_train_all)\n",
    "model_ada = AD_train_and_predict(X_train_all, y_train_all)\n",
    "\n",
    "with open('../models/pickle/rf_model.pickle', mode='wb') as fp:\n",
    "    pickle.dump(model_rf, fp)\n",
    "\n",
    "with open('../models/pickle/lgbm_model.pickle', mode='wb') as fp:\n",
    "    pickle.dump(model_lgbm, fp)\n",
    "\n",
    "with open('../models/pickle/cat_model.pickle', mode='wb') as fp:\n",
    "    pickle.dump(model_cat, fp)\n",
    "\n",
    "with open('../models/pickle/xgb_model.pickle', mode='wb') as fp:\n",
    "    pickle.dump(model_xgb, fp)\n",
    "\n",
    "with open('../models/pickle/ada_model.pickle', mode='wb') as fp:\n",
    "    pickle.dump(model_ada, fp)\n",
    "\n",
    "#特徴の重要度データフレームを作成\n",
    "feature_dataframe = pd.DataFrame( {'features': feats,\n",
    "     'Random Forest feature importances': model_rf.feature_importances_,\n",
    "     'Lightgbm  feature importances': model_lgbm.feature_importances_,\n",
    "     'CatBoost feature importances': model_cat.feature_importances_,\n",
    "     'XGBoost feature importances': model_xgb.feature_importances_,\n",
    "     'AdaBoost feature importances': model_ada.feature_importances_,\n",
    "    })\n",
    "\n",
    "feature_dataframe.to_csv('../data/interim/feature_dataframe.csv', encoding=\"shift_jis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第2モデルの学習データを作成\n",
    "base_predictions_train = pd.DataFrame({\n",
    "     'RandomForest': model_rf.predict(train_x),\n",
    "     'Lightgbm': model_lgbm.predict(train_x),\n",
    "     'CatBoost': model_cat.predict(train_x).ravel(),\n",
    "     'XGBoost': model_xgb.predict(train_x),\n",
    "     'AdaBoost': model_ada.predict(train_x)\n",
    "    })\n",
    "\n",
    "base_predictions_train.to_csv('../data/interim/base_predictions_train.csv')\n",
    "\n",
    "#第2モデルのテストデータを作成\n",
    "base_predictions_test = pd.DataFrame( {\n",
    "     'RandomForest': model_rf.predict(test_x),\n",
    "     'Lightgbm': model_lgbm.predict(test_x),\n",
    "     'CatBoost': model_cat.predict(test_x).ravel(),\n",
    "     'XGBoost': model_xgb.predict(test_x),\n",
    "     'AdaBoost': model_ada.predict(test_x)\n",
    "    })\n",
    "\n",
    "base_predictions_test.to_csv('../data/interim/base_predictions_test.csv')\n",
    "\n",
    "gbm = xgbt.XGBClassifier(\n",
    "                 #learning_rate = 0.02,\n",
    "                 random_state=0,\n",
    "                 n_estimators= 2000,\n",
    "                 max_depth= 4,\n",
    "                 min_child_weight= 2,\n",
    "                 #gamma=1,\n",
    "                 gamma=0.9,\n",
    "                 subsample=0.8,\n",
    "                 colsample_bytree=0.8,\n",
    "                 objective= 'binary:logistic',\n",
    "                 nthread= -1,\n",
    "                 scale_pos_weight=1).fit(base_predictions_train, train_y)\n",
    "\n",
    "predictions = gbm.predict(base_predictions_test)\n",
    "\n",
    "logging.debug('predictions.shape: {}'.format(predictions.shape))\n",
    "\n",
    "with open('../data/interim/stacking_model.pickle', mode='wb') as fp:\n",
    "    pickle.dump(gbm, fp)\n",
    "\n",
    "#CSVファイルの作成\n",
    "StackingSubmission = pd.DataFrame({ '決裁区分': predictions})\n",
    "StackingSubmission.to_csv('../data/processed/StackingSubmission.csv', index=False, encoding=\"shift_jis\")\n",
    "\n",
    "logging.debug('accuracy_score: {}'.format(accuracy_score(predictions, test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIME\n",
    "\n",
    "#クラス名(今回は「同意」「条件付同意」) defaults.jsonにて定義\n",
    "class_names = config['class_name']\n",
    "\n",
    "#可変の説明変数(例：申請金額、金利など) LIMEの結果に出力するものを、この変数に定義されたものだけに絞る。 defaults.jsonにて定義\n",
    "variable_features = config['variable_features']\n",
    "\n",
    "#カテゴリ変数 defaults.jsonにて定義\n",
    "#categorical_features = config['categorical_features']\n",
    "\n",
    "# テスト用サンプル\n",
    "test_sample = test_x[2:3]\n",
    "\n",
    "#RandomForestモデルでのLIMEの結果\n",
    "lime_result_rf = lime_predict(\n",
    "                    model=model_rf,\n",
    "                    X_train_all= train_x, \n",
    "                    y_train_all= train_y, \n",
    "                    x_test=test_sample, \n",
    "                    feature_names=feats,\n",
    "                    num_features=len(feats), \n",
    "                    class_names=class_names,\n",
    "                    discretize_continuous=False,\n",
    "                    variable_features=variable_features\n",
    "                    #categorical_features=categorical_features\n",
    "                    )\n",
    "\n",
    "#XGBoostでのLIMEの結果\n",
    "lime_result_xgb = lime_predict(\n",
    "                    model=model_xgb,\n",
    "                    X_train_all= train_x, \n",
    "                    y_train_all= train_y, \n",
    "                    x_test=test_sample,\n",
    "                    feature_names=feats,\n",
    "                    num_features=len(feats), \n",
    "                    class_names=class_names,\n",
    "                    discretize_continuous=False,\n",
    "                    variable_features=variable_features\n",
    "                    #categorical_features=categorical_features\n",
    "                    )\n",
    "\n",
    "#LightGBMモデルでのLIMEの結果\n",
    "lime_result_lgbm = lime_predict(\n",
    "                    model=model_lgbm,\n",
    "                    X_train_all= train_x, \n",
    "                    y_train_all= train_y, \n",
    "                    x_test=test_sample,\n",
    "                    feature_names=feats,\n",
    "                    num_features=len(feats), \n",
    "                    class_names=class_names,\n",
    "                    discretize_continuous=False,\n",
    "                    variable_features=variable_features\n",
    "                    #categorical_features=categorical_features\n",
    "                    )\n",
    "\n",
    "#CatboostモデルでのLIMEの結果\n",
    "lime_result_cat = lime_predict(\n",
    "                    model=model_cat,\n",
    "                    X_train_all= train_x, \n",
    "                    y_train_all= train_y, \n",
    "                    x_test=test_sample,\n",
    "                    feature_names=feats,\n",
    "                    num_features=len(feats), \n",
    "                    class_names=class_names,\n",
    "                    discretize_continuous=False,\n",
    "                    variable_features=variable_features\n",
    "                    #categorical_features=categorical_features\n",
    "                    )\n",
    "\n",
    "#AdaboostモデルでのLIMEの結果\n",
    "lime_result_ada = lime_predict(\n",
    "                    model=model_ada,\n",
    "                    X_train_all= train_x, \n",
    "                    y_train_all= train_y, \n",
    "                    x_test=test_sample,\n",
    "                    feature_names=feats,\n",
    "                    num_features=len(feats), \n",
    "                    class_names=class_names,\n",
    "                    discretize_continuous=False,\n",
    "                    variable_features=variable_features\n",
    "                    #categorical_features=categorical_features\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果１\n",
    "# 同意か要見直し協議か　割合表示\n",
    "\n",
    "model_list = [\n",
    "                model_rf,\n",
    "                model_lgbm,\n",
    "                model_cat,\n",
    "                model_xgb,\n",
    "                model_ada\n",
    "            ]\n",
    "\n",
    "model_summary_table(model_list, test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果２\n",
    "# 結果１と判断された根拠をLIMEを使ってランキング表示\n",
    "x = PrettyTable()\n",
    "x.field_names = ['ランキング', '判断根拠']\n",
    "for i, feature in enumerate(lime_result_rf):\n",
    "    x.add_row([i+1, feature[0]])\n",
    "print(x.get_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果３\n",
    "# グラフ用のdataframe取得\n",
    "df_x_train = df_load_datasets(feats)\n",
    "# テスト用サンプル\n",
    "df_test_sample = df_x_train[2:3]\n",
    "\n",
    "#LIMEによって導き出された特徴量を訓練データと比較する為のグラフ描画\n",
    "graph_lime_predict_features(lime_result_rf, df_x_train, df_test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果４\n",
    "# 類似している協議書の番号を出力\n",
    "# cos類似度を計算する\n",
    "\n",
    "print('今回の協議と類似しているものは')\n",
    "print(cosine_similar(df_test_sample,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
